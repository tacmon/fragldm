# GeoLDM项目条件生成功能实现指南

## 一、条件生成功能简介

GeoLDM中的"条件生成"是指基于特定分子属性（如极化率、能隙等）定向生成具有目标属性的分子结构。在QM9数据集中，支持的条件属性包括：
- `alpha`：分子极化率
- `gap`：HOMO-LUMO能隙
- `homo`：最高占据分子轨道
- `lumo`：最低未占据分子轨道
- `mu`：分子偶极矩
- `Cv`：恒容热容

本文档将引导您完成从开始到实现第一个epoch条件生成训练的完整流程。

## 二、环境准备

1. **进入项目目录**：
   ```bash
   cd /app/GeoLDM-main
   ```

2. **确认安装依赖**：
   ```bash
   pip install -r requirements.txt
   ```

3. **确认GPU可用**：
   ```bash
   nvidia-smi
   ```
   确保有足够的GPU内存用于训练（条件生成训练需要较大的显存）。

## 三、数据准备

条件生成模型使用QM9数据集的后半部分进行训练，这在命令行参数中通过`--dataset qm9_second_half`指定。系统会自动下载并处理数据，无需手动操作。

如果想查看数据集配置，可以查看：
```bash
cat configs/datasets_config.py
```

## 四、启动条件生成训练

以下是启动条件生成训练的完整命令，我们以`alpha`属性（分子极化率）为例：

```bash
python main_qm9.py --exp_name exp_cond_alpha \
--model egnn_dynamics \
--lr 1e-4 \
--nf 192 \
--n_layers 9 \
--save_model True \
--diffusion_steps 1000 \
--sin_embedding False \
--n_epochs 3000 \
--n_stability_samples 500 \
--diffusion_noise_schedule polynomial_2 \
--diffusion_noise_precision 1e-5 \
--dequantization deterministic \
--include_charges False \
--diffusion_loss_type l2 \
--batch_size 64 \
--normalize_factors [1,8,1] \
--conditioning alpha \
--dataset qm9_second_half \
--train_diffusion \
--trainable_ae \
--latent_nf 1 \
--wandb_usr [你的wandb用户名] \
--test_epochs 1
```

这里关键的参数是：
- `--conditioning alpha`：指定条件生成的属性为分子极化率
- `--dataset qm9_second_half`：使用QM9数据集的后半部分训练
- `--test_epochs 1`：每个epoch后进行测试（为了观察第一个epoch的结果）

## 五、第一个Epoch训练流程详解

当你执行上述命令后，系统将执行以下步骤，完成第一个epoch的训练：

### 1. 初始化阶段
程序首先会解析命令行参数，并进行以下初始化操作：

- **加载数据集信息**：
  ```python
  dataset_info = get_dataset_info(args.dataset, args.remove_h)
  ```
  系统会加载QM9数据集的后半部分的相关信息。

- **设置设备**：
  ```python
  device = torch.device("cuda" if args.cuda else "cpu")
  ```
  检测并设置训练设备（GPU或CPU）。

- **初始化WandB**：
  如果未使用`--no_wandb`参数，系统会初始化WandB以跟踪实验。
  ```python
  wandb.init(entity=args.wandb_usr, name=args.exp_name, project='e3_diffusion_qm9', ...)
  ```

### 2. 数据加载
系统会加载并准备QM9数据集：

```python
dataloaders, charge_scale = dataset.retrieve_dataloaders(args)
```

### 3. 条件属性处理
程序会读取条件属性（本例中为alpha）并计算其归一化参数：

```python
property_norms = compute_mean_mad(dataloaders, args.conditioning, args.dataset)
```

这一步很关键，系统会计算指定属性（alpha）的均值和平均绝对偏差(MAD)，用于后续归一化操作。

### 4. 模型初始化
系统会初始化条件生成的潜在扩散模型：

```python
model, nodes_dist, prop_dist = get_latent_diffusion(args, device, dataset_info, dataloaders['train'])
```

在条件生成中，`prop_dist`对象会被初始化用于属性条件处理：

```python
prop_dist.set_normalizer(property_norms)
```

### 5. 优化器设置
系统会设置优化器，默认使用Adam优化器：

```python
optim = get_optim(args, model)
```

### 6. 训练第一个Epoch
训练函数将执行以下操作：

```python
train_epoch(args=args, loader=dataloaders['train'], epoch=0, model=model, ...)
```

在`train_epoch`函数中，将执行以下核心步骤：

- **遍历训练数据**：程序会遍历训练数据集中的每个批次
- **条件处理**：对于每个批次，系统会处理条件属性（alpha）
  ```python
  context = prepare_context(args.conditioning, batch, property_norms)
  ```
- **前向传播**：通过模型进行前向传播，计算损失
- **反向传播**：计算梯度并更新模型参数
- **记录指标**：将训练损失和其他指标记录到WandB
- **梯度裁剪**：如果设置了`clip_grad`参数，则进行梯度裁剪

### 7. 第一个Epoch结束后的评估
由于我们设置了`--test_epochs 1`，在第一个epoch结束后，程序会进行以下评估：

```python
analyze_and_save(args=args, epoch=0, model_sample=model_ema, ...)
nll_val = test(args=args, loader=dataloaders['valid'], epoch=0, ...)
nll_test = test(args=args, loader=dataloaders['test'], epoch=0, ...)
```

这将评估模型在验证集和测试集上的性能，并生成一些样本分子进行分析。

### 8. 模型保存
如果第一个epoch后的验证性能是目前最好的（这必然是最好的，因为是第一个epoch），程序会保存模型：

```python
utils.save_model(optim, 'outputs/%s/optim.npy' % args.exp_name)
utils.save_model(model, 'outputs/%s/generative_model.npy' % args.exp_name)
```

保存的模型将位于`outputs/exp_cond_alpha/`目录下。

## 六、观察训练结果

第一个epoch完成后，您可以通过以下方式观察结果：

### 1. 通过WandB查看
如果已启用WandB，您可以在WandB网站上查看训练损失、验证损失和其他指标的图表。

### 2. 查看输出目录
检查`outputs/exp_cond_alpha/`目录，该目录包含：
```bash
ls outputs/exp_cond_alpha/
```
您会看到保存的模型文件，如`generative_model.npy`、`optim.npy`等。

### 3. 查看生成的分子
第一个epoch可能还不会生成高质量的分子，但您可以尝试使用以下命令查看生成的分子：
```bash
python eval_conditional_qm9.py --generators_path outputs/exp_cond_alpha --property alpha --n_sweeps 10 --task qualitative
```

## 七、条件生成的实际应用

完成第一个epoch的训练后，您可以选择：

1. **继续训练**：第一个epoch通常不足以获得良好的模型，可以继续训练更多轮次
   
2. **使用预训练模型**：如果不想等待完整训练，可以下载项目提供的预训练模型

3. **评估条件生成能力**：
   要评估条件生成模型的性能，需要先训练一个属性分类器：
   ```bash
   cd qm9/property_prediction
   python main_qm9_prop.py --num_workers 2 --lr 5e-4 --property alpha --exp_name exp_class_alpha --model_name egnn
   ```
   
   然后评估生成的分子：
   ```bash
   python eval_conditional_qm9.py --generators_path outputs/exp_cond_alpha --classifiers_path qm9/property_prediction/outputs/exp_class_alpha --property alpha --iterations 100 --batch_size 100 --task edm
   ```

## 八、条件生成参数调整建议

如果第一个epoch后发现训练不稳定或效果不佳，可以考虑调整以下参数：

- **条件影响强度**：可以通过调整`--normalize_factors`参数中与条件相关的值来控制条件的影响强度
- **学习率**：如果训练不稳定，可以降低学习率，如从`1e-4`改为`5e-5`
- **批量大小**：如果GPU内存允许，可以增加批量大小以获得更稳定的训练
- **模型复杂度**：可以调整`--nf`和`--n_layers`参数以改变模型复杂度
